{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zap\n",
    "import pypsa\n",
    "from zap.tests import network_examples as examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pypsa.io:Imported network texas_7node.nc has buses, carriers, generators, lines, loads, storage_units\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyPSA Network\n",
       "Components:\n",
       " - Bus: 7\n",
       " - Carrier: 17\n",
       " - Generator: 176\n",
       " - Line: 12\n",
       " - Load: 7\n",
       " - StorageUnit: 14\n",
       "Snapshots: 48"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn = examples.load_example_network('texas_7node')\n",
    "pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:zap.importers.pypsa:Importing Generator with 136 devices.\n",
      "INFO:zap.importers.pypsa:Importing Load with 7 devices.\n",
      "INFO:zap.importers.pypsa:Importing ACLine with 12 devices.\n",
      "INFO:zap.importers.pypsa:Importing StorageUnit with 14 devices.\n"
     ]
    }
   ],
   "source": [
    "net, devices = zap.importers.load_pypsa_network(pn, power_unit=1e3, cost_unit=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamrantehranchi/Library/Caches/pypoetry/virtualenvs/zap-qb0btW3r-py3.12/lib/python3.12/site-packages/cvxpy/reductions/solvers/solving_chain.py:356: FutureWarning: \n",
      "    You specified your problem should be solved by ECOS. Starting in\n",
      "    CXVPY 1.6.0, ECOS will no longer be installed by default with CVXPY.\n",
      "    Please either add ECOS as an explicit install dependency to your project\n",
      "    or switch to our new default solver, Clarabel, by either not specifying a\n",
      "    solver argument or specifying ``solver=cp.CLARABEL``. To suppress this\n",
      "    warning while continuing to use ECOS, you can filter this warning using\n",
      "    Python's ``warnings`` module until you are using 1.6.0.\n",
      "    \n",
      "  warnings.warn(ECOS_DEP_DEPRECATION_MSG, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "results = net.dispatch(devices=devices, time_horizon=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_index = 0\n",
    "results.power[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "/Users/kamrantehranchi/Local_Documents/zap/zap/exporters/pypsa.py:400: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  n.generators_t[attr][name] = df.loc[name]\n",
      "INFO:zap.exporters.pypsa:Exported network with 7 buses and 48 snapshots\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyPSA Network\n",
       "Components:\n",
       " - Bus: 7\n",
       " - Generator: 136\n",
       " - Line: 12\n",
       " - Load: 7\n",
       " - StorageUnit: 14\n",
       "Snapshots: 48"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zap_pypsa = zap.exporters.export_to_pypsa(net, devices, results, snapshots=pn.snapshots)\n",
    "zap_pypsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bus0</th>\n",
       "      <th>bus1</th>\n",
       "      <th>bus2</th>\n",
       "      <th>bus3</th>\n",
       "      <th>bus4</th>\n",
       "      <th>bus5</th>\n",
       "      <th>bus6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <th>timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"48\" valign=\"top\">2050</th>\n",
       "      <th>2050-02-01 00:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 01:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 02:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 03:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 04:00:00</th>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 05:00:00</th>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 06:00:00</th>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 07:00:00</th>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 08:00:00</th>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 09:00:00</th>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 10:00:00</th>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "      <td>3.452973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 11:00:00</th>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 12:00:00</th>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 13:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 14:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 15:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 16:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 17:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 18:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 19:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 20:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 21:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 22:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-01 23:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 00:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 01:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 02:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 03:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 04:00:00</th>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "      <td>3.926348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 05:00:00</th>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 06:00:00</th>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 07:00:00</th>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 08:00:00</th>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 09:00:00</th>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 10:00:00</th>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 11:00:00</th>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "      <td>3.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 12:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 13:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 14:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 15:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 16:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 17:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 18:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 19:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 20:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 21:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 22:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050-02-02 23:00:00</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bus0        bus1        bus2        bus3  \\\n",
       "period timestep                                                              \n",
       "2050   2050-02-01 00:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 01:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 02:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 03:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 04:00:00    3.926348    3.926348    3.926348    3.926348   \n",
       "       2050-02-01 05:00:00    3.619017    3.619017    3.619017    3.619017   \n",
       "       2050-02-01 06:00:00    3.452973    3.452973    3.452973    3.452973   \n",
       "       2050-02-01 07:00:00    3.452973    3.452973    3.452973    3.452973   \n",
       "       2050-02-01 08:00:00    3.452973    3.452973    3.452973    3.452973   \n",
       "       2050-02-01 09:00:00    3.452973    3.452973    3.452973    3.452973   \n",
       "       2050-02-01 10:00:00    3.452973    3.452973    3.452973    3.452973   \n",
       "       2050-02-01 11:00:00    3.619017    3.619017    3.619017    3.619017   \n",
       "       2050-02-01 12:00:00    3.926348    3.926348    3.926348    3.926348   \n",
       "       2050-02-01 13:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 14:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 15:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 16:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 17:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 18:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 19:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 20:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 21:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 22:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-01 23:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 00:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 01:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 02:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 03:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 04:00:00    3.926348    3.926348    3.926348    3.926348   \n",
       "       2050-02-02 05:00:00    3.619017    3.619017    3.619017    3.619017   \n",
       "       2050-02-02 06:00:00    3.619017    3.619017    3.619017    3.619017   \n",
       "       2050-02-02 07:00:00    3.619017    3.619017    3.619017    3.619017   \n",
       "       2050-02-02 08:00:00    3.619017    3.619017    3.619017    3.619017   \n",
       "       2050-02-02 09:00:00    3.619017    3.619017    3.619017    3.619017   \n",
       "       2050-02-02 10:00:00    3.619017    3.619017    3.619017    3.619017   \n",
       "       2050-02-02 11:00:00    3.619017    3.619017    3.619017    3.619017   \n",
       "       2050-02-02 12:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 13:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 14:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 15:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 16:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 17:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 18:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 19:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 20:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 21:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 22:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "       2050-02-02 23:00:00  100.000000  100.000000  100.000000  100.000000   \n",
       "\n",
       "                                  bus4        bus5        bus6  \n",
       "period timestep                                                 \n",
       "2050   2050-02-01 00:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 01:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 02:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 03:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 04:00:00    3.926348    3.926348    3.926348  \n",
       "       2050-02-01 05:00:00    3.619017    3.619017    3.619017  \n",
       "       2050-02-01 06:00:00    3.452973    3.452973    3.452973  \n",
       "       2050-02-01 07:00:00    3.452973    3.452973    3.452973  \n",
       "       2050-02-01 08:00:00    3.452973    3.452973    3.452973  \n",
       "       2050-02-01 09:00:00    3.452973    3.452973    3.452973  \n",
       "       2050-02-01 10:00:00    3.452973    3.452973    3.452973  \n",
       "       2050-02-01 11:00:00    3.619017    3.619017    3.619017  \n",
       "       2050-02-01 12:00:00    3.926348    3.926348    3.926349  \n",
       "       2050-02-01 13:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 14:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 15:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 16:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 17:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 18:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 19:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 20:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 21:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 22:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-01 23:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 00:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 01:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 02:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 03:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 04:00:00    3.926348    3.926348    3.926348  \n",
       "       2050-02-02 05:00:00    3.619017    3.619017    3.619017  \n",
       "       2050-02-02 06:00:00    3.619017    3.619017    3.619017  \n",
       "       2050-02-02 07:00:00    3.619017    3.619017    3.619017  \n",
       "       2050-02-02 08:00:00    3.619017    3.619017    3.619017  \n",
       "       2050-02-02 09:00:00    3.619017    3.619017    3.619017  \n",
       "       2050-02-02 10:00:00    3.619017    3.619017    3.619017  \n",
       "       2050-02-02 11:00:00    3.619017    3.619017    3.619017  \n",
       "       2050-02-02 12:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 13:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 14:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 15:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 16:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 17:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 18:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 19:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 20:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 21:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 22:00:00  100.000000  100.000000  100.000000  \n",
       "       2050-02-02 23:00:00  100.000000  100.000000  100.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zap_pypsa.buses_t.marginal_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zap",
   "language": "python",
   "name": "zap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
